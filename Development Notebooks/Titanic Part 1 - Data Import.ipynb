{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Classification - Data Cleansing (Part 1)\n",
    "\n",
    "This is my first ever ipython notebook, which includes some simple playing about with python to get to grips with this environment.\n",
    "\n",
    "\n",
    "\n",
    "All of the below is based on inputting and cleaning up data for the Titanic: Machine Learning from Disaster Kaggle competition.  \n",
    "\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "This is part 1 of my series of creating a solution to this problem as my first attempt at creating a machine learning model now I've finished training.  All previous models I built were courtesy of Andrew Ng's fantastic coursera courses - \n",
    "\n",
    "https://www.coursera.org/learn/machine-learning <br>\n",
    "https://www.coursera.org/specializations/deep-learning\n",
    "\n",
    "Below notes are my initial notes as someone with a SAS/SQL background.\n",
    "\n",
    "Please note that everything here is simply just testing to get to grips with transferring to python, as such I will be using suboptimal coding methodology in order to explore different ways of doing things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First importing some relevant packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to import and view the data and see some useful functions below.\n",
    "\n",
    "Also lets look at all of the different variables on our input and make some notes as to how we're going to pre-process them.\n",
    "\n",
    "### Objectives\n",
    "The overall objective is to get a matrix of values to feed into our eventual ML algorithm.  \n",
    "\n",
    "Hence we want to get rid of all of our text values and replace them with numbers and if appropriate, convert those to One-Hot (OH) encoded matrices to feed into our final algorithm.\n",
    "\n",
    "Then we will want to normalize our numerical fields to speed up convergence later.\n",
    "\n",
    "The below cell contains a compilation of useful functions for personal reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data from raw csv file\n",
    "full_set = pd.read_csv('D:/Datasets/Titanic/train.csv')\n",
    "\n",
    "#use below to get metadata\n",
    "#full_set.info()\n",
    "\n",
    "#below is the top X rows for pandas\n",
    "#full_set.head(10)\n",
    "\n",
    "#below gives us the group by syntax, note that by default it imports all columns so differs slightly from SQL.\n",
    "#fixed_set.groupby('Embarked').count()\n",
    "\n",
    "#Creating a new column as a substring of original\n",
    "#fixed_set['Deck'] = fixed_set.Cabin.str[0]\n",
    "\n",
    "#Getting null/not null values as a pseudo where clause\n",
    "#this is equiv of where cabin is not null in SQL\n",
    "#full_set[full_set['Cabin'].notnull()]\n",
    "\n",
    "\n",
    "#some data cleansing functions - they can be chained as below\n",
    "#full_set.Cabin.str.strip().str.lower().str.replace(' ', '')\n",
    "\n",
    "\n",
    "#Below lines produce a dataset of all the observations where cabin is present\n",
    "#cabin_set = full_set[full_set['Cabin'].notnull()]\n",
    "#This is getting where the second value is a string to verify\n",
    "#cabin_set[cabin_set['Cabin'].str[1].str.isalpha() == True]\n",
    "\n",
    "#Dropping columns\n",
    "#full_set = full_set.drop(['Name', 'Ticket'], axis=1)\n",
    "\n",
    "#Some code from another implementation to convert to One-Hot arrays - the get_dummies function can handle this for us\n",
    "#pd.get_dummies(model_data,columns=['Sex','Embarked'],drop_first=True)\n",
    "\n",
    "#Case when condition example from redundant code  I later removed\n",
    "#full_set.loc(full_set.Deckstr == 'A', 'Deck') = 1\n",
    "\n",
    "#Other more efficient case whenning\n",
    "#dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "#Joining example\n",
    "#pd.merge(full_set, cabin_set, on='PassengerId', how='left')\n",
    "\n",
    "\n",
    "full_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "So the first thing to do is to look at our data and evaluate how to treat each feature in turn.  The below data was obtained by using a series of group by statements on the input dataframe.\n",
    "\n",
    "### PassengerID - \n",
    "We will not be feeding this array into the ML algorithm, instead we will retain the order along the m-axis of our data and use this as a join key when we come to re-merge the data back together for producing a final submission file.\n",
    "\n",
    "### Survived - \n",
    "\n",
    "This will be lifted and used as our y vector with which to compute our cost function.\n",
    "\n",
    "### Pclass - \n",
    "1 - 216<br>\n",
    "2 - 184<br>\n",
    "3 - 491<br>\n",
    "\n",
    "As this is a numerical band with 3 categories, can convert simply to a OH vector.\n",
    "\n",
    "### Name - \n",
    "While name may yield some information as to the social class of the person as this is a small project we shall ignore this for now.  \n",
    "\n",
    "Maybe this could be an avenue for improvement later by using some name embeddings to derive social class and thus likelihood to survive, however this information is likely to be derived from gender/age/fare by our algorithm.\n",
    "\n",
    "Other similar algorithms have used the length of the name as a feature so maybe this could be an avenue to explore.\n",
    "\n",
    "### Gender -\n",
    "female - 314<br>\n",
    "male - 577<br>\n",
    "\n",
    "We can apply a OH classification here.\n",
    "\n",
    "### Age - \n",
    "There is no need to band/categorize here, instead we will implement normalization later.\n",
    "\n",
    "### SibSP -\n",
    "0 -\t608 <br>\n",
    "1 - 209 <br>\n",
    "2 -\t28<br>\n",
    "3 -\t16 <br>\n",
    "4 -\t18 \t<br>\n",
    "5 -\t5 <br>\n",
    "8 -\t7 \t<br>\n",
    "\n",
    "Simple number of siblings/spouses field.  As this has few values that are close together we can just import this column with no manipulation needed\n",
    "\n",
    "### Parch -\n",
    "0 -\t678 <br>\t\n",
    "1 -\t118 \t<br>\n",
    "2 -\t80 <br>\n",
    "3 -\t5 \t<br>\n",
    "4 -\t4 <br>\n",
    "5 -\t5 <br>\n",
    "6 -\t1 <br>\n",
    "\n",
    "We will treat this exactly the same as siblings/spouses as no manipulation needed.\n",
    "\n",
    "### Ticket - \n",
    "While this may have some codes indicating the type of ticket bought, for simplicity we're going to assume the majority of the ticket is just a random integer used as an identifier. \n",
    "\n",
    "As such this information can be dropped as the information is likely to be more accurately captured by the fare.\n",
    "\n",
    "### Fare - \n",
    "see age<br>\n",
    "\n",
    "### Cabin - \n",
    "This data seemed to be a deck/class followed by a number on first inspection, however it appears some people have multiple rooms (each room is cancatenated).\n",
    "\n",
    "We will have to do some data cleansing to export the classes to convert to OH vectors.\n",
    "\n",
    "\n",
    "### Embarked - \n",
    "C - 168<br>\n",
    "Q - 77<br>\n",
    "S - 644<br>\n",
    "\n",
    "Another simple OH vector transform can take care of this for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleansing Cabin\n",
    "\n",
    "As we identified above cabin will require some more data cleansing so that is going to the the focus of the below cell.  The below shows the initial intuitions.\n",
    "\n",
    "The process will be to split this out into two features - \n",
    "\n",
    "## Room\n",
    "\n",
    "This will be an integer, we will have a look at the range of values to decide whether or not to apply a linear transform to the class.\n",
    "\n",
    "For simplicity's sake we will only take the first room in the case of passengers with multiple rooms (later on we could take number of rooms as an additional feature perhaps).\n",
    "\n",
    "## Deck\n",
    "\n",
    "Here we will figure out the range of values the characters can take and the assign an integer value to each to feed in as a ML feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_x</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_y</th>\n",
       "      <th>canc</th>\n",
       "      <th>Deckstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C85</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C123</td>\n",
       "      <td>C123</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>E46</td>\n",
       "      <td>E46</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin_x Embarked Cabin_y  canc Deckstr  \n",
       "0      0         A/5 21171   7.2500     NaN        S     NaN   NaN     NaN  \n",
       "1      0          PC 17599  71.2833     C85        C     C85   C85       C  \n",
       "2      0  STON/O2. 3101282   7.9250     NaN        S     NaN   NaN     NaN  \n",
       "3      0            113803  53.1000    C123        S    C123  C123       C  \n",
       "4      0            373450   8.0500     NaN        S     NaN   NaN     NaN  \n",
       "5      0            330877   8.4583     NaN        Q     NaN   NaN     NaN  \n",
       "6      0             17463  51.8625     E46        S     E46   E46       E  \n",
       "7      1            349909  21.0750     NaN        S     NaN   NaN     NaN  \n",
       "8      2            347742  11.1333     NaN        S     NaN   NaN     NaN  \n",
       "9      0            237736  30.0708     NaN        C     NaN   NaN     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Below lines produce a dataset of all the observations where cabin is present\n",
    "cabin_set = full_set[full_set['Cabin'].notnull()]\n",
    "#This is getting where the second value is a string to verify\n",
    "\n",
    "#Dropping columns we don't care about\n",
    "cabin_set = cabin_set[['PassengerId','Cabin']]\n",
    "\n",
    "#Concatenating our original field to remove all the spaces\n",
    "cabin_set['canc'] = cabin_set['Cabin'].str.replace(' ', '')\n",
    "\n",
    "\n",
    "\n",
    "#cabin_set.head(100)\n",
    "\n",
    "#DEALING WITH DECK FIRST\n",
    "\n",
    "#Below is a validation step for 2nd character\n",
    "#cabin_set[cabin_set['canc'].str[1].str.isalpha() == True]\n",
    "\n",
    "#It appears that 4 records have the second char as character, the rest have room numbers next to them\n",
    "\n",
    "#It is unclear what is going on with these 4 however I suspect its simply a missing room number and they in fact have 2 rooms.\n",
    "\n",
    "#So for these 4 we will take the first char as the deck and next integer value as the room\n",
    "#This may not be accurate but it should not throw off our algorithm too badly as its only 4 values\n",
    "\n",
    "#We unfortunately cannot give bespoke treatment to them as we have to have a general treatment\n",
    "#This is because we have to have a general linear transform for our submission set.\n",
    "\n",
    "#This leaves Deck as simply taking the first character which is by definition always a character\n",
    "cabin_set['Deckstr'] = cabin_set['canc'].str[0]\n",
    "\n",
    "#left join our deck classification back onto our original data frame\n",
    "deck_set = pd.merge(full_set, cabin_set, on='PassengerId', how='left')\n",
    "\n",
    "#The above may have been dealt with easier in place however I decided to split it out to better \n",
    "#visualize the data when working\n",
    "\n",
    "#Plus it gives a frame of reference for how to merge data in pandas\n",
    "deck_set.head(10)\n",
    "\n",
    "\n",
    "#DEALING WITH ROOM\n",
    "#Having manually looked at room, this will likely be 50+ unique categories since we cannot treat it as numeric\n",
    "#This will add a lot more features to our model but may not actually give much in the way of classification information\n",
    "#Thus I have decided to omit rooms for now\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age and Fare normalization\n",
    "\n",
    "Now we have the cabin field ready for converting to OH vectors, now to take care of our numerical fields - Age and Fare.\n",
    "\n",
    "For these we are simply going to normalize them using the following formula - \n",
    "\n",
    "new $ x_i = \\dfrac{x_i - \\mu}{max(x) - min(x)}$\n",
    "\n",
    "Null values will be ignored and should not matter to our algorithm.\n",
    "\n",
    "We can also choose to divide by the variance should dividing by the range be a bad choice.\n",
    "\n",
    "##  Dealing with NaN values\n",
    "\n",
    "As NaN values can invalidate any summation over matrices we will also need to account for NaN values.  \n",
    "\n",
    "Fortunately as we have normalized about our mean we can simply use 0 as a replacement for NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_x</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_y</th>\n",
       "      <th>canc</th>\n",
       "      <th>Deckstr</th>\n",
       "      <th>Norm_age</th>\n",
       "      <th>Norm_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.096747</td>\n",
       "      <td>-0.048707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C85</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0.104309</td>\n",
       "      <td>0.076277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046483</td>\n",
       "      <td>-0.047390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C123</td>\n",
       "      <td>C123</td>\n",
       "      <td>C</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.040786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>-0.047146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.046349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>E46</td>\n",
       "      <td>E46</td>\n",
       "      <td>E</td>\n",
       "      <td>0.305364</td>\n",
       "      <td>0.038370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.348066</td>\n",
       "      <td>-0.021723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.033917</td>\n",
       "      <td>-0.041128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.197275</td>\n",
       "      <td>-0.004164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin_x Embarked Cabin_y  canc Deckstr  \\\n",
       "0      0         A/5 21171   7.2500     NaN        S     NaN   NaN     NaN   \n",
       "1      0          PC 17599  71.2833     C85        C     C85   C85       C   \n",
       "2      0  STON/O2. 3101282   7.9250     NaN        S     NaN   NaN     NaN   \n",
       "3      0            113803  53.1000    C123        S    C123  C123       C   \n",
       "4      0            373450   8.0500     NaN        S     NaN   NaN     NaN   \n",
       "5      0            330877   8.4583     NaN        Q     NaN   NaN     NaN   \n",
       "6      0             17463  51.8625     E46        S     E46   E46       E   \n",
       "7      1            349909  21.0750     NaN        S     NaN   NaN     NaN   \n",
       "8      2            347742  11.1333     NaN        S     NaN   NaN     NaN   \n",
       "9      0            237736  30.0708     NaN        C     NaN   NaN     NaN   \n",
       "\n",
       "   Norm_age  Norm_fare  \n",
       "0 -0.096747  -0.048707  \n",
       "1  0.104309   0.076277  \n",
       "2 -0.046483  -0.047390  \n",
       "3  0.066611   0.040786  \n",
       "4  0.066611  -0.047146  \n",
       "5  0.000000  -0.046349  \n",
       "6  0.305364   0.038370  \n",
       "7 -0.348066  -0.021723  \n",
       "8 -0.033917  -0.041128  \n",
       "9 -0.197275  -0.004164  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First get our means\n",
    "age_mean = deck_set['Age'].mean()\n",
    "fare_mean = deck_set['Fare'].mean()\n",
    "\n",
    "#Next get our denominator\n",
    "age_range = deck_set['Age'].max() - deck_set['Age'].min()\n",
    "fare_range = deck_set['Fare'].max() - deck_set['Fare'].min()\n",
    "\n",
    "#Finally create new fields in our dataframe which are normalized versions\n",
    "deck_set['Norm_age'] = (deck_set['Age'] - age_mean) / age_range\n",
    "deck_set['Norm_fare'] = (deck_set['Fare'] - fare_mean) / fare_range\n",
    "\n",
    "#Replace NaN with 0\n",
    "deck_set['Norm_age'].fillna(0, inplace=True)\n",
    "deck_set['Norm_fare'].fillna(0, inplace=True)\n",
    "\n",
    "deck_set.head(10)\n",
    "\n",
    "#Dividing by the range seems okay for now, we can revisit this later if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting our One-Hot Vectors\n",
    "\n",
    "Now to deal with all of our categories by converting them all into one-hot vectors.\n",
    "\n",
    "This should be a relatively straightforward process iterating over all of our categorical features.\n",
    "\n",
    "After that we can finally put it all together in a final dataframe for exporting into numpy arrays to feed into our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Norm_age</th>\n",
       "      <th>Norm_fare</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>pclass_1.0</th>\n",
       "      <th>pclass_2.0</th>\n",
       "      <th>pclass_3.0</th>\n",
       "      <th>pclass_nan</th>\n",
       "      <th>...</th>\n",
       "      <th>Emb_nan</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_T</th>\n",
       "      <th>Deck_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.096747</td>\n",
       "      <td>-0.048707</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104309</td>\n",
       "      <td>0.076277</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.046483</td>\n",
       "      <td>-0.047390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.040786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>-0.047146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.046349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.305364</td>\n",
       "      <td>0.038370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.348066</td>\n",
       "      <td>-0.021723</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033917</td>\n",
       "      <td>-0.041128</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.197275</td>\n",
       "      <td>-0.004164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Norm_age  Norm_fare  SibSp  Parch  pclass_1.0  \\\n",
       "0            1         0 -0.096747  -0.048707      1      0           0   \n",
       "1            2         1  0.104309   0.076277      1      0           1   \n",
       "2            3         1 -0.046483  -0.047390      0      0           0   \n",
       "3            4         1  0.066611   0.040786      1      0           1   \n",
       "4            5         0  0.066611  -0.047146      0      0           0   \n",
       "5            6         0  0.000000  -0.046349      0      0           0   \n",
       "6            7         0  0.305364   0.038370      0      0           1   \n",
       "7            8         0 -0.348066  -0.021723      3      1           0   \n",
       "8            9         1 -0.033917  -0.041128      0      2           0   \n",
       "9           10         1 -0.197275  -0.004164      1      0           0   \n",
       "\n",
       "   pclass_2.0  pclass_3.0  pclass_nan    ...     Emb_nan  Deck_A  Deck_B  \\\n",
       "0           0           1           0    ...           0       0       0   \n",
       "1           0           0           0    ...           0       0       0   \n",
       "2           0           1           0    ...           0       0       0   \n",
       "3           0           0           0    ...           0       0       0   \n",
       "4           0           1           0    ...           0       0       0   \n",
       "5           0           1           0    ...           0       0       0   \n",
       "6           0           0           0    ...           0       0       0   \n",
       "7           0           1           0    ...           0       0       0   \n",
       "8           0           1           0    ...           0       0       0   \n",
       "9           1           0           0    ...           0       0       0   \n",
       "\n",
       "   Deck_C  Deck_D  Deck_E  Deck_F  Deck_G  Deck_T  Deck_nan  \n",
       "0       0       0       0       0       0       0         1  \n",
       "1       1       0       0       0       0       0         0  \n",
       "2       0       0       0       0       0       0         1  \n",
       "3       1       0       0       0       0       0         0  \n",
       "4       0       0       0       0       0       0         1  \n",
       "5       0       0       0       0       0       0         1  \n",
       "6       0       0       1       0       0       0         0  \n",
       "7       0       0       0       0       0       0         1  \n",
       "8       0       0       0       0       0       0         1  \n",
       "9       0       0       0       0       0       0         1  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate one hot vector dataframes for each of the categorical fields\n",
    "p_set = pd.get_dummies(deck_set.Pclass, prefix='pclass', dummy_na = True)\n",
    "gen_set = pd.get_dummies(deck_set.Sex, prefix='Gen', dummy_na = True)\n",
    "emb_set = pd.get_dummies(deck_set.Embarked, prefix='Emb', dummy_na = True)                        \n",
    "dek_set = pd.get_dummies(deck_set.Deckstr, prefix='Deck', dummy_na = True)\n",
    "\n",
    "#Define our final output dataframe\n",
    "out_set = pd.concat([deck_set[['PassengerId', 'Survived', 'Norm_age', 'Norm_fare', 'SibSp', 'Parch']], \n",
    "                     p_set, \n",
    "                     gen_set, \n",
    "                     emb_set, \n",
    "                     dek_set], axis=1)\n",
    "\n",
    "out_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting our data\n",
    "Now we have our data all in one place and looking good!\n",
    "\n",
    "The final step is to split it out into the relevant matrices and convert to numpy arrays.\n",
    "\n",
    "Our final outputs should be - <br>\n",
    "*X* an $(m * n_x)$ matrix where $n_x$ denotes the number of features. <br>\n",
    "*Y* an $(m * 1)$ vector of our binary classification ground truth vector.\n",
    "\n",
    "However this would only give us our full training set!\n",
    "\n",
    "As we have only been provided labels for our training set and not the submission set we should also split out a cross validation set to evaluate our outputs.\n",
    "\n",
    "So given our out_set shape is $(891, 26)$  we can take 100 observations out for our cross validation set and have the remaining 791 for training.\n",
    "\n",
    "We should really take this as a random sample based on our data distribution, however given the small dataset size its probably okay to just take a cutoff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmenting data\n",
    "X_Train_df = out_set.head(791)\n",
    "X_CV_df = out_set.tail(100)\n",
    "\n",
    "#Getting our Y vectors\n",
    "Y_Train = X_Train_df['Survived'].values\n",
    "Y_CV = X_CV_df['Survived'].values\n",
    "\n",
    "#Dropping columns we don't want to feed into our ML algorithm\n",
    "X_Train_df = X_Train_df.drop(['PassengerId', 'Survived'], axis=1)\n",
    "X_CV_df = X_CV_df.drop(['PassengerId', 'Survived'], axis=1)\n",
    "\n",
    "#Getting our X vectors\n",
    "X_Train = X_Train_df.values\n",
    "X_CV = X_CV_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "Now we have our training data cleansed and ready to use!\n",
    "\n",
    "However there's two final things remaining, we will want to put all of this into functions we can call easily for our later notebooks and we have to do all of this manipulation to our submission data also.\n",
    "\n",
    "And not forgetting we have to create our submission file so we will want three functions - \n",
    "* Cleanse_Training_Data(dataframe)\n",
    "* Cleanse_Submission_Data(dataframe)\n",
    "* Create_Submission_Output(dataframe, Y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our Training Set\n",
    "def Cleanse_Training_Data(train_df):\n",
    "    #Getting our Deck\n",
    "    train_df['canc'] = train_df['Cabin'].str.replace(' ', '')\n",
    "    train_df['Deckstr'] = train_df['canc'].str[0]\n",
    "    \n",
    "    #Normalizing age/fare\n",
    "    age_mean = train_df['Age'].mean()\n",
    "    fare_mean = train_df['Fare'].mean()\n",
    "    age_range = train_df['Age'].max() - train_df['Age'].min()\n",
    "    fare_range = train_df['Fare'].max() - train_df['Fare'].min()\n",
    "\n",
    "    train_df['Norm_age'] = (train_df['Age'] - age_mean) / age_range\n",
    "    train_df['Norm_fare'] = (train_df['Fare'] - fare_mean) / fare_range\n",
    "    \n",
    "    #Replace NaN with 0\n",
    "    train_df['Norm_age'].fillna(0, inplace=True)\n",
    "    train_df['Norm_fare'].fillna(0, inplace=True)\n",
    "    \n",
    "    #Generate one hot vector dataframes for each of the categorical fields\n",
    "    p_set = pd.get_dummies(train_df.Pclass, prefix='pclass', dummy_na = True)\n",
    "    gen_set = pd.get_dummies(train_df.Sex, prefix='Gen', dummy_na = True)\n",
    "    emb_set = pd.get_dummies(train_df.Embarked, prefix='Emb', dummy_na = True)                        \n",
    "    dek_set = pd.get_dummies(train_df.Deckstr, prefix='Deck', dummy_na = True)\n",
    "\n",
    "    #Define our final output dataframe\n",
    "    out_set = pd.concat([train_df[['Survived', 'Norm_age', 'Norm_fare', 'SibSp', 'Parch']], \n",
    "                     p_set, \n",
    "                     gen_set, \n",
    "                     emb_set, \n",
    "                     dek_set], axis=1)\n",
    "    \n",
    "    \n",
    "    #Segmenting data\n",
    "    X_Train_df = out_set.head(791)\n",
    "    X_CV_df = out_set.tail(100)\n",
    "\n",
    "    #Getting our Y vectors\n",
    "    Y_Train = X_Train_df['Survived'].values\n",
    "    Y_CV = X_CV_df['Survived'].values\n",
    "\n",
    "    #Dropping columns we don't want to feed into our ML algorithm\n",
    "    X_Train_df = X_Train_df.drop(['Survived'], axis=1)\n",
    "    X_CV_df = X_CV_df.drop(['Survived'], axis=1)\n",
    "\n",
    "    #Getting our X vectors\n",
    "    X_Train = X_Train_df.values\n",
    "    X_CV = X_CV_df.values\n",
    "    \n",
    "    return X_Train, X_CV, Y_Train, Y_CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 24)\n"
     ]
    }
   ],
   "source": [
    "#Testing our function\n",
    "X_Train_t, X_CV_t, Y_Train_t, Y_CV_t = Cleanse_Training_Data(full_set)\n",
    "    \n",
    "print(X_CV_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File\n",
    "\n",
    "Now to create our submission file functions.  First lets load our submission dataset and have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan Cervin</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7538</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330972</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>Caldwell, Mr. Albert Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>Abrahim, Mrs. Joseph (Sophie Halaut Easu)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2657</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>Davies, Mr. John Samuel</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A/4 48871</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "5          897       3                    Svensson, Mr. Johan Cervin    male   \n",
       "6          898       3                          Connolly, Miss. Kate  female   \n",
       "7          899       2                  Caldwell, Mr. Albert Francis    male   \n",
       "8          900       3     Abrahim, Mrs. Joseph (Sophie Halaut Easu)  female   \n",
       "9          901       3                       Davies, Mr. John Samuel    male   \n",
       "\n",
       "    Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0     330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0     363272   7.0000   NaN        S  \n",
       "2  62.0      0      0     240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0     315154   8.6625   NaN        S  \n",
       "4  22.0      1      1    3101298  12.2875   NaN        S  \n",
       "5  14.0      0      0       7538   9.2250   NaN        S  \n",
       "6  30.0      0      0     330972   7.6292   NaN        Q  \n",
       "7  26.0      1      1     248738  29.0000   NaN        S  \n",
       "8  18.0      0      0       2657   7.2292   NaN        C  \n",
       "9  21.0      2      0  A/4 48871  24.1500   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_set = pd.read_csv('D:/Datasets/Titanic/test.csv')\n",
    "\n",
    "sub_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like a very similar format but without Survived, for obvious reasons.  Thus in order to load this we can use a replication of the above function but omit any references to survived.\n",
    "\n",
    "However we will require one new output - a PassengerID vector to cancatenate on to our eventual $\\hat{y}$ so we can easily merge and create our submission file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our Training Set\n",
    "def Cleanse_Submission_Data(sub_df):\n",
    "    #Getting our Deck\n",
    "    sub_df['canc'] = sub_df['Cabin'].str.replace(' ', '')\n",
    "    sub_df['Deckstr'] = sub_df['canc'].str[0]\n",
    "    \n",
    "    #Normalizing age/fare\n",
    "    age_mean = sub_df['Age'].mean()\n",
    "    fare_mean = sub_df['Fare'].mean()\n",
    "    age_range = sub_df['Age'].max() - sub_df['Age'].min()\n",
    "    fare_range = sub_df['Fare'].max() - sub_df['Fare'].min()\n",
    "\n",
    "    sub_df['Norm_age'] = (sub_df['Age'] - age_mean) / age_range\n",
    "    sub_df['Norm_fare'] = (sub_df['Fare'] - fare_mean) / fare_range\n",
    "    \n",
    "    #Replace NaN with 0\n",
    "    sub_df['Norm_age'].fillna(0, inplace=True)\n",
    "    sub_df['Norm_fare'].fillna(0, inplace=True)\n",
    "    \n",
    "    #Generate one hot vector dataframes for each of the categorical fields\n",
    "    p_set = pd.get_dummies(sub_df.Pclass, prefix='pclass', dummy_na = True)\n",
    "    gen_set = pd.get_dummies(sub_df.Sex, prefix='Gen', dummy_na = True)\n",
    "    emb_set = pd.get_dummies(sub_df.Embarked, prefix='Emb', dummy_na = True)                        \n",
    "    dek_set = pd.get_dummies(sub_df.Deckstr, prefix='Deck', dummy_na = True)\n",
    "\n",
    "    #Define our final output dataframe\n",
    "    out_set = pd.concat([sub_df[['PassengerId', 'Norm_age', 'Norm_fare', 'SibSp', 'Parch']], \n",
    "                     p_set, \n",
    "                     gen_set, \n",
    "                     emb_set, \n",
    "                     dek_set], axis=1)\n",
    "    \n",
    "    #Inserting to account for T deck\n",
    "    out_set.insert(23, 'Deck_T', 0) \n",
    "    \n",
    "    sub_ID = out_set['PassengerId'].values\n",
    "    \n",
    "    #Dropping columns we don't want to feed into our ML algorithm\n",
    "    out_set = out_set.drop(['PassengerId'], axis=1)\n",
    "\n",
    "    #Getting our X vectors\n",
    "    Submis_set = out_set.values\n",
    "    \n",
    "    return Submis_set, sub_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 24)\n",
      "(418,)\n"
     ]
    }
   ],
   "source": [
    "#Testing submission to make sure it matches\n",
    "sub_out, id_set = Cleanse_Submission_Data(sub_set)\n",
    "\n",
    "print(sub_out.shape)\n",
    "print(id_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission File\n",
    "\n",
    "The final function is to generate the file output in the correct format to submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1\n",
       "5          897         0\n",
       "6          898         1\n",
       "7          899         0\n",
       "8          900         1\n",
       "9          901         0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First lets have a look at the output format\n",
    "fin_set = pd.read_csv('D:/Datasets/Titanic/gender_submission.csv')\n",
    "\n",
    "fin_set.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears there's only 2 columns, our prediction $\\hat{y}$ and the passenger_ID field, so we can simply cancatenate our 2 vectors together and we have our submission file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create our function to put our vectors into a dataframe we can export to Kaggle.\n",
    "def Create_output_frame(id_set, y_hat):\n",
    "    #After much frustration I decided on this method because it actually worked.\n",
    "    #There is likely a better method that I will figure out at a later date.\n",
    "    out_df = pd.DataFrame(id_set, columns=['PassengerId'])\n",
    "    out_df['Survived'] = y_hat\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0\n",
       "5          897         0\n",
       "6          898         0\n",
       "7          899         0\n",
       "8          900         0\n",
       "9          901         0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First we will need to define a y_hat to test.  Lets just take a vector of all zeros for simplicity\n",
    "pred_test = np.zeros(418, dtype='int64')\n",
    "\n",
    "test_out = Create_output_frame(id_set, pred_test)\n",
    "\n",
    "test_out.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to build some models as we have our data imported nicely, see part 2 for the first small model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
